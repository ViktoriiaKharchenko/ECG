# -*- coding: utf-8 -*-
"""Normal_Arrhythmia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gFXNoj1PavTUJjTf9Bbjq94kQQePtHKm
"""

import numpy as np
from os import listdir
from os.path import isfile, join
import pandas as pd
import scipy.io as sio
import matplotlib.pyplot as plt # Отрисовка изображений

from sklearn.model_selection import train_test_split
from keras.callbacks import ModelCheckpoint
from tensorflow.keras import utils
from sklearn.preprocessing import StandardScaler 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization,Conv1D, GlobalAveragePooling1D, MaxPooling1D,Flatten
from sklearn.preprocessing import MinMaxScaler 
from tensorflow import keras
from tensorflow.keras import regularizers

datasetPath = 'drive/MyDrive/Colab Notebooks/datasets/AF_vs_Normal/dataAF_Normal.txt'
resultPath = 'drive/MyDrive/Colab Notebooks/datasets/AF_vs_Normal/typeAF_Normal.txt'
x_train = np.loadtxt(datasetPath)
y_train = np.loadtxt(resultPath)
print(x_train.shape)
print(y_train.shape)
boolArr = y_train == 1
print(boolArr)
noizy = y_train[boolArr]
print(noizy.shape)

datasetPath = 'drive/MyDrive/Colab Notebooks/datasets/AF_vs_Normal/dataValidationAF_Normal.txt'
resultPath = 'drive/MyDrive/Colab Notebooks/datasets/AF_vs_Normal/typeValidationAF_Normal.txt'
x_val1 = np.loadtxt(datasetPath)
y_val1 = np.loadtxt(resultPath)
print(x_val1.shape)
print(y_val1.shape)
x_val, x_test, y_val, y_test = train_test_split(x_val1, y_val1, test_size=0.3, shuffle=True)
y_test2 = y_test

x_train = x_train.reshape(x_train.shape[0],900,1)
y_train=y_train.reshape(y_train.shape[0],1)
x_val = x_val.reshape(x_val.shape[0],900,1)
y_val=y_val.reshape(y_val.shape[0],1)
x_test = x_test.reshape(x_test.shape[0],900,1)
y_test=y_test.reshape(y_test.shape[0],1)
print(y_train.shape)

y_train = utils.to_categorical(y_train, 2)
y_test = utils.to_categorical(y_test, 2)
y_val = utils.to_categorical(y_val, 2)
print(y_train.shape)

def create_model():
  opt = keras.optimizers.Adam(learning_rate=0.001)
  model = Sequential()
  model.add(Conv1D(64, 50, activation='relu',kernel_regularizer=regularizers.l1(l=0.01), input_shape=(900, 1)))
  model.add(BatchNormalization())
  model.add(MaxPooling1D(5))
  model.add(Conv1D(32, 30, activation='relu'))
  model.add(BatchNormalization())
  model.add(MaxPooling1D(5))
  model.add(Dropout(0.5))
  model.add(Conv1D(32, 20, activation='relu'))
  model.add(BatchNormalization())
  model.add(Flatten())
  model.add(Dense(64, kernel_initializer='normal', activation='relu'))
  model.add(BatchNormalization())
  model.add(Dropout(0.5))
  model.add(Dense(32, kernel_initializer='normal', activation='relu'))
  model.add(BatchNormalization())
  model.add(Dropout(0.5))
  model.add(Dense(2, kernel_initializer='normal', activation='softmax'))
  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])
  return model

# Создаём пустую сеть
model = create_model()
checkpointer = ModelCheckpoint(filepath='drive/MyDrive/Colab Notebooks/models/Best_AFvsN_mode.h5', monitor='val_accuracy', verbose=1, save_best_only=True)

# Обучаем сеть
history = model.fit(x_train, 
          y_train,
          batch_size=250, 
          epochs=30,
          validation_data=(x_val,y_val),
          verbose=1, shuffle=True,callbacks=[checkpointer])
model.save('drive/MyDrive/Colab Notebooks/models/AFvsN_mode.h5')
# keras.models.save_model(model,'drive/MyDrive/Colab Notebooks/modelNoize.h5')
# for i in range(9):
#   model = keras.models.load_model('drive/MyDrive/Colab Notebooks/modelNoize.h5')
#   history = model.fit(x_train, 
#           y_train,
#           batch_size=200, 
#           epochs=10,
#           validation_data=(x_val,y_val), # Указываем 20% случайных примеров для проверочной выборки
#           verbose=1, shuffle=True, callbacks=[checkpointer])
#   keras.models.save_model(model,'drive/MyDrive/Colab Notebooks/modelNoize.h5')

model = keras.models.load_model('drive/MyDrive/Colab Notebooks/models/Best_AFvsN_model2.h5')
scores = model.evaluate(x_test, y_test, verbose=1)
print(scores)
print("Доля верных ответов на тестовых данных, в процентах: ", round(scores[1] * 100, 2), "%", sep="")

# Выводим график точности на обучающей выборке
# label - имя графика в легенде
plt.plot(history.history['accuracy'], 
         label='Доля верных ответов на обучающем наборе')

# Выводим график точности на проверочной выборке
plt.plot(history.history['val_accuracy'], 
         label='Доля верных ответов на проверочном наборе')

# Выводим подписи осей
plt.xlabel('Эпоха обучения')
plt.ylabel('Доля верных ответов')

# Выводим легенду
plt.legend()
plt.show()

plt.plot(history.history['loss'], 
         label='Ошибка на обучающем наборе')
plt.plot(history.history['val_loss'], 
         label='Ошибка на проверочном наборе')
plt.xlabel('Эпоха обучения')
plt.ylabel('Ошибка')
plt.legend()
plt.show()

trueN = 0
falseN = 0
trueAF = 0 
falseAF = 0

model = keras.models.load_model('drive/MyDrive/Colab Notebooks/models/Best_AFvsN_mode.h5')
# datasetPath = 'drive/MyDrive/Colab Notebooks/dataManual.txt'
# resultPath = 'drive/MyDrive/Colab Notebooks/typeManual.txt'
# x_test = np.loadtxt(datasetPath)
# y_test = np.loadtxt(resultPath)

for i in range(len(x_test)) :
  x = x_test[i].reshape(1,900,1)
  prediction = model.predict(x)
  prediction = np.argmax(prediction)
  if prediction == y_test2[i]:
    if prediction == 0 :
      trueN = trueN + 1
    else:
       trueAF = trueAF + 1
  else :
    if prediction == 0 :
       falseN = falseN + 1
       #print(i)
    else :
      falseAF = falseAF + 1
      #print(i)
print(trueN) 
print(falseN) 
print(trueAF) 
print(falseAF)